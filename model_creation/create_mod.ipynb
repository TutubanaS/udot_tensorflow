{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing modules\n",
        "These line should be run only for colab"
      ],
      "metadata": {
        "id": "xxJbw7pgg8fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install --upgrade tensorflow\n",
        "pip install scann\n",
        "pip install -q tensorflow-recommenders\n",
        "pip install -q tensorflow_hub\n",
        "#these line should be run only on colab"
      ],
      "metadata": {
        "id": "duh1-wzF17kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing modules\n",
        "Import of:\n",
        "\n",
        "\n",
        "*   Tensorflow\n",
        "*   Tensorflow Recommenders: contains the ScaNN layer we are going to use\n",
        "*   Tensorflow Hub: contains the embedding model we are going to pass to the ScaNN layer\n",
        "*   os: for path managment\n"
      ],
      "metadata": {
        "id": "mXO5odWBhGE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import os \n",
        "import shutil"
      ],
      "metadata": {
        "id": "UKOsQWfphp7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the index\n",
        "\n",
        "The following function creates the index given a dataset of embeddings.\n"
      ],
      "metadata": {
        "id": "nwpHM1lWh9vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(dataset, embedding_model = None):\n",
        "  \"\"\"\n",
        "  :param dataset: a tensorflow dataset with the embedded version of the space we want to query in\n",
        "  :param embedding_model: a tensorflow model(loaded with tf hub or thorugh keras load_model function) that embeds strings into multidimensional vectors. The embedder should be the same as the one used to create :param dataset:\n",
        "  :return: the index model \n",
        "  \"\"\"\n",
        "\n",
        "  index = tfrs.layers.factorized_top_k.ScaNN() #this is the model without the \n",
        "\n",
        "  test_value = tf.constant(list(dataset.take(1).as_numpy_iterator()))\n",
        "  if embedding_model is not None:\n",
        "    index = tfrs.layers.factorized_top_k.ScaNN(query_model = embedding_model)\n",
        "    test_value = tf.constat([''])\n",
        "\n",
        "  index.index_from_dataset(dataset.batch(512))\n",
        "\n",
        "  _ = index(test_value)\n",
        "\n",
        "  return index"
      ],
      "metadata": {
        "id": "JSti_UGniC6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and saving the index in SaveModel format\n",
        "\n",
        "The following function generates the servable version of the model."
      ],
      "metadata": {
        "id": "oBQnqGQrjP9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_save(dataset:tf.Tensor, save_path:str, version:int = 1, embedding_model:tf.keras.Model = None, zip:bool = False):\n",
        "  \"\"\"\n",
        "  :param dataset: a tensorflow dataset with the embedded version of the space we want to query in\n",
        "  :param save_path: a path, as string, that saves the model \n",
        "  :param version: creates a subfolder to the \n",
        "  :param embedding_model: a tensorflow model(loaded with tf hub or thorugh keras load_model function) that embeds strings into multidimensional vectors. The embedder should be the same as the one used to create :param dataset:\n",
        "  :param zip: a boolean, if it is true, creates a zip of the model saved\n",
        "  :return: the index model \n",
        "  \"\"\"\n",
        "\n",
        "  index = create_index(dataset, embedding_model) #creating the index\n",
        "\n",
        "  path = os.path.join(save_path, str(version)) #adding the version subfolder\n",
        "\n",
        "  index.save(filepath = path) #saving the index\n",
        "  \n",
        "  if zip:\n",
        "    shutil.make_archive(save_path, 'zip') #zipping if zip is True\n",
        "  \n",
        "  return index"
      ],
      "metadata": {
        "id": "VwihpDCvjJdz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}